{
 "metadata": {
  "name": "",
  "signature": "sha256:eaa8da5e822bd291488903edebbff44f4b6129479ec53e8cbc6d9f696c65a30c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Intentifying persistent motion fields\n",
      "\n",
      "This piece of code attempts to focus on features which can be tracked over a long time (i.e. 30 minutes) and which rather move along a \"straight line\". The motivation is to use only those motion patterns for forecasting/nowcasting which have a minimum level of persistence (and ignore individual features that show a rather erratic behaviour).  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab\n",
      "import wradlib\n",
      "import trackpy as tp\n",
      "import fipy\n",
      "import cv2\n",
      "import numpy as np\n",
      "import os\n",
      "from scipy import stats\n",
      "from matplotlib import animation\n",
      "from scipy.ndimage import zoom\n",
      "import datetime\n",
      "import warnings\n",
      "warnings.simplefilter('once', DeprecationWarning)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Reading the data\n",
      "\n",
      "Data is from the German Weather Service: the so called RY product represents rainfall intensity composite for the whole of Germany in 5 minute intervals. \n",
      "\n",
      "Spatial resolution: `1 x 1 km`; spatial extent: `900 x 900 km`.\n",
      "\n",
      "**Information required from user**\n",
      "\n",
      "- specify the directory `datadir` where you store the RY data (unpack the ry.rar archive there).\n",
      "- select a specific interval by commenting/uncommenting the `dtimes` lines.\n",
      "- decide whether you need to reduce the resolution (downsize the image by a `downsizeby`) in order to avoid memory problems"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set data directory\n",
      "datadir = r\"E:\\src\\python\\nowcast\\trackpy\\ry\"\n",
      "\n",
      "# Original grid dimensions\n",
      "nx = 900\n",
      "ny = 900\n",
      "\n",
      "# pixel size (in meters)\n",
      "dx = 1000.\n",
      "dy = 1000.\n",
      "\n",
      "# Downsize by factor \"downsizeby\"\n",
      "#    downsizeby = 1 will leave the dimensions unchanged,\n",
      "#    but for a 900x900 km grid, downsizing might be \n",
      "#    required in order to avoid MemoryError\n",
      "downsizeby = 2\n",
      "\n",
      "# interval between observations (in seconds)\n",
      "interval = 300\n",
      "\n",
      "# Set time window\n",
      "##dtimes = wradlib.util.from_to(\"2008-06-02 17:00:00\", \"2008-06-02 19:00:00\", 300)\n",
      "##dtimes = wradlib.util.from_to(\"2015-04-26 17:00:00\", \"2015-04-26 19:00:00\", 300)\n",
      "##dtimes = wradlib.util.from_to(\"2015-03-29 17:00:00\", \"2015-03-29 19:00:00\", 300)\n",
      "dtimes = wradlib.util.from_to(\"2015-04-01 17:00:00\", \"2015-04-01 19:00:00\", interval)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute grid dimensions and grid coordinates after resampling\n",
      "dx2, dy2 = dx*downsizeby, dy*downsizeby\n",
      "nx2, ny2 = nx/downsizeby, ny/downsizeby\n",
      "\n",
      "X2, Y2 = np.meshgrid( np.arange(0,nx2*dx2, dx2), np.arange(0,ny2*dy2, dy2) )\n",
      "\n",
      "# Define container\n",
      "frames = np.zeros( (len(dtimes), nx2, ny2 ) )\n",
      "\n",
      "# Move to data directory\n",
      "os.chdir(datadir)\n",
      "\n",
      "# Read the data, convert to dBZ, and downsize\n",
      "for i, dtime in enumerate(dtimes):\n",
      "    fname = dtime.strftime(\"raa01-ry_10000-%y%m%d%H%M-dwd---bin\")\n",
      "    frames[i] = zoom( wradlib.io.read_RADOLAN_composite(fname, missing=0)[0], 1./downsizeby, order=1)\n",
      "    frames[i] = wradlib.trafo.decibel( wradlib.zr.r2z(frames[i]) )\n",
      "    frames[i][frames[i]<0] = 0 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using trackpy to detect and track features\n",
      "\n",
      "- detection via `tp.batch`\n",
      "- tracking/linking via `tp.link_df`\n",
      "\n",
      "The idea is to track only features that represent \"persistent motion patterns\". Please note that those features/tracks will be filtered out which have not been tracked over at least 6 times steps (i.e. 6 * 5 minutes = 30 minutes). This is due to a specific requirement: I want to detect the rather persistent motion."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# FEATURE DETECTION\n",
      "diameter = 11\n",
      "feats = tp.batch(frames, diameter=diameter, minmass=500., invert=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# FEATURE TRACKING\n",
      "# Assumed maximum diplacement velocity: 150 km/h\n",
      "#   (see http://www.meteo.fr/cic/wsn05/resumes_longs/2.14-73.pdf)\n",
      "#   Corresponds to about 12 km in 5 minutes\n",
      "#   This is required for the search radius.\n",
      "#   BEWARE: You need to provide this as a number of pixels, so you need to consider downsizeby\n",
      "#   We set memory=0 because we do not expect features to disappear and reappear again.\n",
      "tracks = tp.link_df(feats, int(12/downsizeby), memory=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# FILTERING TRACKS: Only persistent tracks survive (i.e. which persist over min_tsteps)\n",
      "min_tsteps = 6\n",
      "tracks1 = tp.filter_stubs(tracks, min_tsteps)\n",
      "# Compare the number of particles in the unfiltered and filtered data.\n",
      "print 'Features before:', tracks['particle'].nunique()\n",
      "print 'Features after:', tracks1['particle'].nunique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Quick diagnostic view at remaining tracks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Quickview at the tracks\n",
      "ax = plt.subplot(111,aspect=\"equal\")\n",
      "tp.plot_traj(tracks1, ax=ax)\n",
      "plt.xlim(0, nx2)\n",
      "plt.ylim(0, ny2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Analyze trajectories: only \"straight\" trajectories survive\n",
      "my = tracks\n",
      "max_p = 0.001\n",
      "ids, dvx, dvy, xmean, ymean = np.array([]), np.array([]), np.array([]), np.array([]), np.array([])\n",
      "for id in np.unique(my.particle).astype(\"i4\"):\n",
      "    sub = my[my.particle==id]\n",
      "    slope, intercept, r_value, p_value, std_err = stats.linregress(sub.x,sub.y)\n",
      "    if p_value < max_p:\n",
      "        # Compute velocity components in m/s\n",
      "        dvx = np.append(dvx, np.mean(np.diff(sub.x)) * dx2 / interval )\n",
      "        dvy = np.append(dvy, np.mean(np.diff(sub.y)) * dy2 / interval )\n",
      "        xmean = np.append(xmean,   np.mean(sub.x)*dx2 )\n",
      "        ymean = np.append(ymean,   np.mean(sub.y)*dy2 )\n",
      "        ids = np.append(ids, id)\n",
      "\n",
      "# Plot remaining arrows over average reflectivity\n",
      "ax = plt.subplot(111,aspect=\"equal\")\n",
      "#plt.imshow(np.mean(frames, axis=0), origin='lower')\n",
      "plt.pcolormesh(X2, Y2, np.mean(frames, axis=0))\n",
      "#tp.plot_traj(my, ax=ax)\n",
      "plt.quiver(xmean, ymean, dvx, dvy, pivot='middle', headwidth=4, headlength=6, color='red')\n",
      "for i, id in enumerate(ids):\n",
      "    plt.text(xmean[i], ymean[i], \"%d\"%id, color=\"white\" )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Animation\n",
      "plotthis = tracks1\n",
      "\n",
      "_plot_style = dict(markersize=diameter, markeredgewidth=2,\n",
      "                       markerfacecolor='none', markeredgecolor='r',\n",
      "                       marker='o', linestyle='none')\n",
      "_imshow_style = dict(interpolation='none',\n",
      "                       cmap=plt.cm.spectral)\n",
      "\n",
      "fig = plt.figure(figsize=(16,8))\n",
      "ax1 = fig.add_subplot(121, aspect=\"equal\")\n",
      "ax2 = fig.add_subplot(122, aspect=\"equal\")\n",
      "\n",
      "im1 = ax1.imshow(frames[0], **_imshow_style)\n",
      "ax1.set_xlim(-0.5, frames[0].shape[1] - 0.5)\n",
      "ax1.set_ylim(-0.5, frames[0].shape[0] - 0.5)\n",
      "title1 = ax1.set_title(dtimes[0].isoformat())\n",
      "#ax1.invert_yaxis()\n",
      "\n",
      "im2 = ax2.imshow(frames[0], **_imshow_style)\n",
      "ax2.set_xlim(-0.5, frames[0].shape[1] - 0.5)\n",
      "ax2.set_ylim(-0.5, frames[0].shape[0] - 0.5)\n",
      "title2 = ax2.set_title(dtimes[0].isoformat())\n",
      "#ax2.invert_yaxis()\n",
      "\n",
      "bubbles, = ax2.plot(plotthis[plotthis[\"frame\"]==0][\"x\"], plotthis[plotthis[\"frame\"]==0][\"y\"], **_plot_style)\n",
      "\n",
      "def animate(i):\n",
      "    im1.set_data(frames[i])\n",
      "    im2.set_data(frames[i])\n",
      "    bubbles.set_data(plotthis[plotthis[\"frame\"]==i][\"x\"], plotthis[plotthis[\"frame\"]==i][\"y\"])\n",
      "    ax1.set_title(dtimes[i].isoformat())\n",
      "    ax2.set_title(dtimes[i].isoformat())\n",
      "    return im1, im2, bubbles, title1, title2\n",
      "\n",
      "#Init only required for blitting to give a clean slate.\n",
      "def init():\n",
      "    im1.set_data(frames[0])\n",
      "    im2.set_data(frames[0])\n",
      "    bubbles.set_data(plotthis[plotthis[\"frame\"]==0][\"x\"], plotthis[plotthis[\"frame\"]==0][\"y\"])\n",
      "    ax1.set_title(dtimes[0].isoformat())\n",
      "    ax2.set_title(dtimes[0].isoformat())\n",
      "    return im1, im2, bubbles, title1, title2\n",
      "\n",
      "ani = animation.FuncAnimation(fig, animate, frames=np.arange(24), interval=100, blit=False)#, init_func=init,\n",
      "#    interval=100, blit=False)#, repeat_delay=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Interpolate displacement vector field (slow!)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def interpolate_velocities(x, y, dvx, dvy, trgx, trgy, Ipol=wradlib.ipol.Idw, **kwargs ):\n",
      "    \"\"\"Interpolates advection velocities in x and y direction.\n",
      "    \n",
      "    This function computes a field of displacement vectors on a\n",
      "    target grid that is given by trgx and trgy. This requires source\n",
      "    displacment vectors which are defined by their location (x and y coordinates)\n",
      "    and their x and y velocity components (dvx, dvy).\n",
      "    \n",
      "    Furthemore, you need to provide an interpolation class from wradlib.ipol\n",
      "    (wradlib.ipol.Idw by default).\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array of floats\n",
      "        x coordinates of source displacement vectors\n",
      "    y : array of floats\n",
      "        y coordinates of source displacement vectors\n",
      "    dvx : array of floats\n",
      "        x component of advection velocity\n",
      "    dvy : array of floats\n",
      "        y component of advection velocity\n",
      "    trgx : array of floats\n",
      "        x coordinates of interpolation targets \n",
      "    trgy : array of floats\n",
      "        y coordinates of interpolation targets\n",
      "    Ipol : an interpolation class from wradlib.ipol\n",
      "        uses wradlib.ipol.Idw by default\n",
      "    kwargs: dictionary of keyword arguments required by Ipol\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    output : dvx_ip, dvy_ip\n",
      "        Interpolated velocity components in x and y direction at locations defined by trgy and trgy.\n",
      "    \n",
      "    \"\"\"\n",
      "    srcxy = np.vstack((x, y)).transpose()\n",
      "    trgxy = np.vstack( (trgx.ravel(), trgy.ravel()) ).transpose()\n",
      "    dvx_ip = wradlib.ipol.interpolate(srcxy, trgxy, dvx, Ipol, **kwargs).reshape((trgx.shape))\n",
      "    dvy_ip = wradlib.ipol.interpolate(srcxy, trgxy, dvy, Ipol, **kwargs).reshape((trgx.shape))\n",
      "    \n",
      "    return dvx_ip, dvy_ip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ip_kwargs = {\"nnearest\":4, \"p\":1.}\n",
      "dvx_ip_tp, dvy_ip_tp = interpolate_velocities(xmean, ymean, dvx, dvy, X2, Y2, **ip_kwargs )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## ...and view the interpolated displacement vector field"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_vector_field(X, Y, dvx, dvy, ith):\n",
      "    \"\"\"Quick view interpolated vector field\n",
      "    \n",
      "    Just to reuse it when working with OpenCV below.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    ith : integer\n",
      "          Plot every ith displacment vector along the grid axes\n",
      "    \"\"\"\n",
      "    nx, ny = X.shape\n",
      "    fig = plt.figure(figsize=(10,10))\n",
      "    ax = fig.add_subplot(111, aspect=\"equal\")\n",
      "    # Average reflectivity over analysis period (just for orientation)\n",
      "    cl = plt.pcolormesh(X, Y, np.mean(frames, axis=0), cmap=\"spectral\")\n",
      "    # Interpolated displacement vector field\n",
      "    plt.quiver(X[0:nx:ith,0:ny:ith], Y[0:nx:ith,0:ny:ith], dvx[0:nx:ith,0:ny:ith], dvy[0:nx:ith,0:ny:ith], \n",
      "               pivot='middle', headwidth=4, headlength=6, color='white')\n",
      "    # Other decorators\n",
      "    plt.grid(color=\"white\")\n",
      "    plt.xlabel(\"kilometers\")\n",
      "    plt.ylabel(\"kilometers\")\n",
      "    cb = plt.colorbar(cl, shrink=0.75)\n",
      "    cb.set_label(\"dBZ\")\n",
      "\n",
      "plot_vector_field(X2, Y2, dvx_ip_tp, dvy_ip_tp, 30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Use fipy to advect the field \n",
      "\n",
      "For field advection we use FiPy, a finite volume PDE solver. It provides stable methods to solve the 2d advection problem. Just consider rainfall intensity as a quantity that is advected with a 2D velocity field. \n",
      "\n",
      "Our worst enemies here: **numerical diffusion** and **performance**. Solving the advection PDE certainly is the performance bottleneck.\n",
      "\n",
      "Memory is a problem, too: at least on my 32-bit Python, I need to reduce the spatial resolution by a factor of 2 in order to get this running."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Some information to numerically solve the initial-boundary vaue problem\n",
      "#   Initial condition\n",
      "init_step = 12\n",
      "#   Boundary condition: always zero (dBZ or rainfall intensity...doesn't matter)\n",
      "boundary = 0. # dBZ\n",
      "#   Forecast time settings\n",
      "lead_time = 3600 # in seconds\n",
      "# CFL number is defined as C = u * dt/dx and typically C_max = 1, so u * dt/dx < C_max yields dt < dx/u\n",
      "dt = 30 # in seconds\n",
      "numsteps = int(lead_time / dt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define the 2D mesh\n",
      "mesh = fipy.Grid2D(dx=dx2, dy=dy2, nx=nx2, ny=ny2)\n",
      "\n",
      "# Set the 2D scalar variable (rainfall intensity or reflectivity)\n",
      "var = fipy.CellVariable(name = \"solution variable\", mesh = mesh, value = frames[init_step].copy().ravel())\n",
      "\n",
      "# Set boundary conditions\n",
      "var.constrain(boundary, mesh.facesLeft)\n",
      "var.constrain(boundary, mesh.facesRight)\n",
      "var.constrain(boundary, mesh.facesBottom)\n",
      "var.constrain(boundary, mesh.facesTop)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set displacement vector field on the same mesh (i.e. convection coefficient - assumed persistent)\n",
      "convCoefftp = fipy.CellVariable(mesh=mesh, value=[dvx_ip_tp.ravel(), dvy_ip_tp.ravel()])\n",
      "\n",
      "# Set the advection equation\n",
      "#   the VanLeerConvectionTerm appears to minimize numerical diffusion compared to the other methods)\n",
      "eq = fipy.TransientTerm() + fipy.VanLeerConvectionTerm(coeff = convCoefftp)\n",
      "##eq = fipy.TransientTerm()  + fipy.FirstOrderAdvectionTerm(coeff=convCoeff)\n",
      "##eq = fipy.TransientTerm() + fipy.ExplicitUpwindConvectionTerm(coeff=convCoeff)\n",
      "##eq = fipy.TransientTerm()  + fipy.ExponentialConvectionTerm(coeff=convCoeff)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Solve the advection equation (SLOW!)\n",
      "#   This is our results container\n",
      "#   index 0 corresponds to our initial condition, so index \"i\" is the \"ith\" forecast step\n",
      "forecast_tp = np.zeros((numsteps+1,nx2,ny2))\n",
      "forecast_tp[0] = frames[init_step].copy()\n",
      "now = datetime.datetime.now()\n",
      "for i in range(numsteps):\n",
      "    eq.solve(var=var, dt=dt)\n",
      "    forecast_tp[i+1] = var.value.reshape((nx2,ny2))\n",
      "print \"Advection took %.1f seconds.\" % (datetime.datetime.now()-now).total_seconds()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Animate forecast and \"reality\"\n",
      "_plot_style = dict(markersize=diameter, markeredgewidth=2,\n",
      "                       markerfacecolor='none', markeredgecolor='r',\n",
      "                       marker='o', linestyle='none')\n",
      "_pcm_style = dict(cmap=plt.cm.spectral, vmin=0., vmax=30.)\n",
      "\n",
      "# Prepare canvas\n",
      "fig = plt.figure(figsize=(16,12))\n",
      "ax1 = plt.subplot2grid((3,4), (0,0), colspan=2, rowspan=2, aspect=\"equal\")\n",
      "ax2 = plt.subplot2grid((3,4), (0,2), colspan=2, rowspan=2, aspect=\"equal\")\n",
      "ax3 = plt.subplot2grid((3,4), (2,0), colspan=4, rowspan=1)\n",
      "\n",
      "# Initialize map of observed rainfall\n",
      "im1 = ax1.pcolormesh(X2, Y2, frames[init_step], **_pcm_style)\n",
      "ax1.grid(color=\"white\")\n",
      "title1 = ax1.set_title(\"Observation\")\n",
      "tstamp1 = ax1.text(50000., 850000., dtimes[0].isoformat(), color=\"white\")\n",
      "\n",
      "# Initialize map of forecast rainfall\n",
      "im2 = ax2.pcolormesh(X2, Y2, forecast_tp[0], **_pcm_style)\n",
      "ax2.grid(color=\"white\")\n",
      "title2 = ax2.set_title(\"Forecast\")\n",
      "tstamp2 = ax2.text(50000., 850000., dtimes[0].isoformat(), color=\"white\")\n",
      "\n",
      "# Initialize decorrelation diagnostics\n",
      "plot_steps = np.arange(0, lead_time/interval)\n",
      "corr1 = plot_steps * np.nan\n",
      "corr2 = plot_steps * np.nan\n",
      "im3 = ax3.plot(plot_steps, np.ma.masked_invalid(corr1), \"b-\", marker=\"o\", label=\"forecast trackpy\")\n",
      "im4 = ax3.plot(plot_steps, np.ma.masked_invalid(corr2), \"r-\", marker=\"o\", label=\"persistence\")\n",
      "ax3.set_xlim(0, len(plot_steps))\n",
      "ax3.set_ylim(0, 1.)\n",
      "ax3.set_xlabel(\"forecast timestep (* 5min)\")\n",
      "ax3.set_ylabel(\"pearson correlation\")\n",
      "ax3.legend()\n",
      "ax3.grid()\n",
      "\n",
      "def animate(i):\n",
      "    # this hack was used to get the orientation right:\n",
      "    #    http://stackoverflow.com/questions/29009743/using-set-array-with-pyplot-pcolormesh-ruins-figure\n",
      "    im1.set_array(frames[init_step+i,:-1,:-1].ravel())\n",
      "    tstamp1.set_text(dtimes[i].isoformat())\n",
      "    # get the right index from forecast (because the forecast time step is different from observation timestep)\n",
      "    i_ = int((interval/dt)*i)\n",
      "    im2.set_array(forecast_tp[i_,:-1,:-1].ravel())\n",
      "    tstamp2.set_text(dtimes[i].isoformat())\n",
      "    if i==0:\n",
      "        corr1[:] = np.nan\n",
      "        corr2[:] = np.nan\n",
      "    corr1[i] = stats.pearsonr(frames[init_step+i].ravel(), forecast_tp[i_].ravel())[0]\n",
      "    im3[0].set_data((plot_steps, np.ma.masked_invalid(corr1)))\n",
      "    corr2[i] = stats.pearsonr(frames[init_step+i].ravel(), frames[init_step].ravel())[0]\n",
      "    im4[0].set_data((plot_steps, np.ma.masked_invalid(corr2)))\n",
      "    return im1, im2, title1, title2, im3, im4\n",
      "\n",
      "ani = animation.FuncAnimation(fig, animate, frames=plot_steps, interval=100, blit=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using OpenCV to detect and track features by using Optical Flow techniques\n",
      "\n",
      "Now we would like to know how tracking methods from OpenCV compare to trackpy. Generally, we would expect OpenCV to work better because there are no underlying assumptions regarding the shape of the objects to track. Then again, trackpy has the great built-in feature that allows you to filter tracks based on their persistence...let's see.\n",
      "\n",
      "As you might have experienced, OpenCV can be cumbersome to build, but this time, I am lucky on Windows, because OpenCV is a standard package in Python(x,y)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set some initial parameters for Optical Flow - something to play with\n",
      "\n",
      "#     FEATURE DETECTION: Parameters for ShiTomasi corner detection\n",
      "feature_params = dict( maxCorners = 200,\n",
      "                       qualityLevel = 0.3,\n",
      "                       minDistance = 7,\n",
      "                       blockSize = 21 )\n",
      "\n",
      "#     FEATURE TRACKING: Parameters for Lucas Kanade Optical Flow technique\n",
      "lk_params = dict( winSize  = (20,20),\n",
      "                  maxLevel = 2,\n",
      "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0))\n",
      "\n",
      "# Our own parameters\n",
      "#    Over which time steps do you want to track\n",
      "trackstart = 6\n",
      "trackend = 13\n",
      "#    For how many time steps should a track persist?\n",
      "min_tsteps = 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Our approach requires 8 bit integers - so we need to normalize our radar data accordingly\n",
      "#   (there might be a more elegant solution...)\n",
      "minval = 0\n",
      "maxval = 59 # dBZ in this case\n",
      "iframes = frames.copy()\n",
      "iframes[iframes<minval] = minval\n",
      "iframes[iframes>maxval] = maxval\n",
      "iframes = ((iframes / maxval)*255).astype(np.uint8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Find \"good\" features to track...\n",
      "old = cv2.goodFeaturesToTrack(iframes[trackstart], mask = None, **feature_params)\n",
      "\n",
      "# Set containers to collect results (time steps in rows, corners in columns)\n",
      "#    all corner's x and y coordinates\n",
      "cornerx = old[:,0,0].reshape((1,-1))\n",
      "cornery = old[:,0,1].reshape((1,-1))\n",
      "#    tracking status (False if a corner could not be tracked to the next image)\n",
      "sts = np.ones((1,len(old)), dtype=np.bool)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Track corners\n",
      "for i in range(trackstart+1, trackend):\n",
      "    # track current corners in next image\n",
      "    new, st, err = cv2.calcOpticalFlowPyrLK(prevImg=iframes[i], nextImg=iframes[i+1], prevPts=old, nextPts=None, **lk_params)\n",
      "    sts = np.vstack( (sts, st.reshape(1,-1).astype(np.bool)))\n",
      "    cornerx = np.vstack( (cornerx,new[:,0,0].reshape(1,-1)) )\n",
      "    cornery = np.vstack( (cornery,new[:,0,1].reshape(1,-1)) )\n",
      "    # new corners will be old in the next loop\n",
      "    old = new"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Analyse tracks and compute average displacement\n",
      "#   white: good track, red: track is too short or not straight enough\n",
      "max_p = 0.01\n",
      "max_err = 0.01\n",
      "dvx, dvy, xmean, ymean = np.array([]), np.array([]), np.array([]), np.array([])\n",
      "stderrs = np.array([])\n",
      "fig = plt.figure(figsize=(12,12))\n",
      "ax = fig.add_subplot(111, aspect=\"equal\")\n",
      "ax.imshow(np.mean(frames[trackstart:trackend], axis=0), origin=\"lower\", cmap=\"spectral\")\n",
      "for i in range(cornerx.shape[1]):\n",
      "    goods = np.where(sts[:,i])[0]\n",
      "    color = \"red\"\n",
      "    if len(goods) > min_tsteps:\n",
      "        slope, intercept, r_value, p_value, std_err = stats.linregress(cornerx[goods,i],cornery[goods,i])\n",
      "        stderrs = np.append(stderrs, std_err)\n",
      "        if (p_value < max_p) and (std_err < max_err):\n",
      "            color=\"white\"\n",
      "            dvx = np.append(dvx, np.mean(np.diff(cornerx[goods,i])) * dx2 / interval )\n",
      "            dvy = np.append(dvy, np.mean(np.diff(cornery[goods,i])) * dy2 / interval )\n",
      "            xmean = np.append(xmean, np.mean(cornerx[goods,i])*dx2 )\n",
      "            ymean = np.append(ymean, np.mean(cornery[goods,i])*dy2 )\n",
      "    ax.plot(cornerx[goods,i], cornery[goods,i],marker=\"None\", color=color, markersize=14, linestyle=\"-\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot remaining arrows over average reflectivity\n",
      "fig = plt.figure(figsize=(12,12))\n",
      "ax = fig.add_subplot(111,aspect=\"equal\")\n",
      "plt.pcolormesh(X2, Y2, np.mean(frames[trackstart:trackend], axis=0), cmap=\"spectral\")\n",
      "#ax.imshow(np.mean(frames[0:trackover], axis=0), origin=\"lower\", cmap=\"spectral\")\n",
      "plt.quiver(xmean, ymean, dvx, dvy, pivot='middle', headwidth=4, headlength=6, color='white')\n",
      "#for i in range(len(dvx)):\n",
      "#    plt.text(xmean[i], ymean[i], \"%d\"%i, color=\"white\" )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Interpolate vector field\n",
      "ip_kwargs = {\"nnearest\":4, \"p\":1.}\n",
      "dvx_ip_cv, dvy_ip_cv = interpolate_velocities(xmean, ymean, dvx, dvy, X2, Y2, **ip_kwargs )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_vector_field(X2, Y2, dvx_ip_cv, dvy_ip_cv, 30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Advect field using fipy - see details above when we did the same for trackpy results\n",
      "\n",
      "#   Reset inital condition\n",
      "var.value = frames[init_step].copy().ravel()\n",
      "\n",
      "#   Set new displacement vector field\n",
      "convCoeffCV = fipy.CellVariable(mesh=mesh, value=[dvx_ip_cv.ravel(), dvy_ip_cv.ravel()])\n",
      "\n",
      "eq = fipy.TransientTerm() + fipy.VanLeerConvectionTerm(coeff = convCoeffCV)\n",
      "\n",
      "# Solve the advection equation (SLOW!)\n",
      "#   This is our results container\n",
      "#   index 0 corresponds to our initial condition, so index \"i\" is the \"ith\" forecast step\n",
      "now = datetime.datetime.now()\n",
      "forecast_cv = np.zeros((numsteps+1,nx2,ny2))\n",
      "forecast_cv[0] = frames[init_step].copy()\n",
      "for i in range(numsteps):\n",
      "    eq.solve(var=var, dt=dt)\n",
      "    forecast_cv[i+1] = var.value.reshape((nx2,ny2))\n",
      "print \"Advection took %.1f seconds.\" % (datetime.datetime.now()-now).total_seconds()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Animate forecast and \"reality\"\n",
      "_plot_style = dict(markersize=12, markeredgewidth=2,\n",
      "                       markerfacecolor='none', markeredgecolor='r',\n",
      "                       marker='o', linestyle='none')\n",
      "_pcm_style = dict(cmap=plt.cm.spectral, vmin=0., vmax=30.)\n",
      "\n",
      "# Prepare canvas\n",
      "fig = plt.figure(figsize=(16,12))\n",
      "ax1 = plt.subplot2grid((3,4), (0,0), colspan=2, rowspan=2, aspect=\"equal\")\n",
      "ax2 = plt.subplot2grid((3,4), (0,2), colspan=2, rowspan=2, aspect=\"equal\")\n",
      "ax3 = plt.subplot2grid((3,4), (2,0), colspan=4, rowspan=1)\n",
      "\n",
      "# Initialize map of observed rainfall\n",
      "im1 = ax1.pcolormesh(X2, Y2, frames[init_step], **_pcm_style)\n",
      "ax1.grid(color=\"white\")\n",
      "title1 = ax1.set_title(\"Observation\")\n",
      "tstamp1 = ax1.text(50000., 850000., dtimes[0].isoformat(), color=\"white\")\n",
      "\n",
      "# Initialize map of forecast rainfall\n",
      "im2 = ax2.pcolormesh(X2, Y2, forecast_cv[0], **_pcm_style)\n",
      "ax2.grid(color=\"white\")\n",
      "title2 = ax2.set_title(\"Forecast\")\n",
      "tstamp2 = ax2.text(50000., 850000., dtimes[0].isoformat(), color=\"white\")\n",
      "\n",
      "# Initialize decorrelation diagnostics\n",
      "plot_steps = np.arange(0, lead_time/interval)\n",
      "corr1 = plot_steps * np.nan\n",
      "corr2 = plot_steps * np.nan\n",
      "corr3 = plot_steps * np.nan\n",
      "im3 = ax3.plot(plot_steps, np.ma.masked_invalid(corr1), \"b-\", marker=\"o\", label=\"forecast cv\")\n",
      "im4 = ax3.plot(plot_steps, np.ma.masked_invalid(corr2), \"r-\", marker=\"o\", label=\"persistence\")\n",
      "im5 = ax3.plot(plot_steps, np.ma.masked_invalid(corr3), \"g-\", marker=\"o\", label=\"forecast trackpy\")\n",
      "ax3.set_xlim(0, len(plot_steps))\n",
      "ax3.set_ylim(0, 1.)\n",
      "ax3.set_xlabel(\"forecast timestep (* 5min)\")\n",
      "ax3.set_ylabel(\"pearson correlation\")\n",
      "ax3.legend()\n",
      "ax3.grid()\n",
      "\n",
      "def animate(i):\n",
      "    # this hack was used to get the orientation right:\n",
      "    #    http://stackoverflow.com/questions/29009743/using-set-array-with-pyplot-pcolormesh-ruins-figure\n",
      "    im1.set_array(frames[init_step+i,:-1,:-1].ravel())\n",
      "    tstamp1.set_text(dtimes[i].isoformat())\n",
      "    # get the right index from forecast (because the forecast time step is different from observation timestep)\n",
      "    i_ = int((interval/dt)*i)\n",
      "    im2.set_array(forecast_cv[i_,:-1,:-1].ravel())\n",
      "    tstamp2.set_text(dtimes[i].isoformat())\n",
      "    if i==0:\n",
      "        corr1[:] = np.nan\n",
      "        corr2[:] = np.nan\n",
      "        corr3[:] = np.nan\n",
      "    corr1[i] = stats.pearsonr(frames[init_step+i].ravel(), forecast_cv[i_].ravel())[0]\n",
      "    im3[0].set_data((plot_steps, np.ma.masked_invalid(corr1)))\n",
      "    corr2[i] = stats.pearsonr(frames[init_step+i].ravel(), frames[init_step].ravel())[0]\n",
      "    im4[0].set_data((plot_steps, np.ma.masked_invalid(corr2)))\n",
      "    corr3[i] = stats.pearsonr(frames[init_step+i].ravel(), forecast_tp[i_].ravel())[0]\n",
      "    im5[0].set_data((plot_steps, np.ma.masked_invalid(corr3)))\n",
      "    return im1, im2, title1, title2, im3, im4, im5\n",
      "\n",
      "ani = animation.FuncAnimation(fig, animate, frames=plot_steps, interval=100, blit=False)\n",
      "#ani.save(\"cv_vs_tp.mp4\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}